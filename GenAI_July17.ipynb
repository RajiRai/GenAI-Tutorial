{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CVGXVM9JT3qLaScIdCvMDDpwGsUli9iD",
      "authorship_tag": "ABX9TyNwTUdc4EpBwOu+AV2LmexN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajiRai/GenAI-Tutorial/blob/main/GenAI_July17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere altair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ibZrjNYbIrD",
        "outputId": "dd4a41bc-7a50-4af4-81cc-8ed22f30bc61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.6.1-py3-none-any.whl (178 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/178.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m174.1/178.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.5/178.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair in /usr/local/lib/python3.10/dist-packages (4.2.2)\n",
            "Collecting boto3<2.0.0,>=1.34.0 (from cohere)\n",
            "  Downloading boto3-1.34.144-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.21.2 (from cohere)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx-sse<0.5.0,>=0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.19.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair) (4.19.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair) (2.0.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair) (0.12.1)\n",
            "Collecting botocore<1.35.0,>=1.34.144 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading botocore-1.34.144-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.0->cohere)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.21.2->cohere)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.21.2->cohere)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair) (0.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.7)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.23.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair) (2.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18->altair) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Installing collected packages: types-requests, parameterized, jmespath, httpx-sse, h11, fastavro, httpcore, botocore, s3transfer, httpx, boto3, cohere\n",
            "Successfully installed boto3-1.34.144 botocore-1.34.144 cohere-5.6.1 fastavro-1.9.5 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 httpx-sse-0.4.0 jmespath-1.0.1 parameterized-0.9.0 s3transfer-0.10.2 types-requests-2.32.0.20240712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RWcEczs_Z5QC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cohere\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import userdata\n",
        "key =userdata.get('Cohere_key')\n",
        "co = cohere.Client(key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [ \"Carson City is the capital city of the American state of Nevada. At the 2010 United States Census, Carson City had a population of 55,274.\",\n",
        "    \"The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\",\n",
        "    \"Charlotte Amalie is the capital and largest city of the United States Virgin Islands. It has about 20,000 people. The city is on the island of Saint Thomas.\",\n",
        "    \"Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\",\n",
        "    \"West Virginia is a state in the Appalachian region of the United States. Its capital and largest city is Charleston. It is often abbreviated W. Va. or simply WV.\",\n",
        "    \"Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states. The federal government (including the United States military) also uses capital punishment.\",\n",
        "    \"North Dakota is a state in the United States. 672,591 people lived in North Dakota in the year 2010. The capital and seat of government is Bismarck.\",\n",
        "    \"Kentucky is a state in the United States. Its capital is Frankfort. It touches the states of Missouri (by the Mississippi River), Illinois, Indiana, Ohio, West Virginia (by the Ohio River), Tennessee and Virginia. There are many rivers in Kentucky\",\n",
        "    \"Micronesia, officially the Federated States of Micronesia, is an island nation in the Pacific Ocean, northeast of Papua New Guinea. The country is a sovereign state in free association with the United States. The capital city of Federated States of Micronesia is Palikir.\",\n",
        "    \"Utah is a state in the west United States. The capital and largest city is Salt Lake City. Utah became a state in the U.S. on January 4, 1896.\"\n",
        "\n",
        "]\n",
        "\n",
        "query = \"What is the capital of the United States?\""
      ],
      "metadata": {
        "id": "3JTRJc3QbFpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rerank endpoint\n",
        "\n",
        "results = co.rerank(query=query,\n",
        "                    model=\"rerank-english-v3.0\",\n",
        "                    documents=docs,\n",
        "                    top_n=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "-rFIVsRXhV8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, r in enumerate(results.results):\n",
        "  print(f\"Document Rank : {idx+1}, Document Index : {r.index}\")\n",
        "  print(f\"Document : {docs[r.index]}\")\n",
        "  print(f\"Relevance Score : {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKP4ktGUjHY-",
        "outputId": "c8bf488f-7ddc-4dc9-ddf2-16b8bb6010b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank : 1, Document Index : 3\n",
            "Document : Washington, D.C. (also known as simply Washington or D.C., and officially as the District of Columbia) is the capital of the United States. It is a federal district. The President of the USA and many major national government offices are in the territory. This makes it the political center of the United States of America.\n",
            "Relevance Score : 1.00\n",
            "\n",
            "\n",
            "Document Rank : 2, Document Index : 5\n",
            "Document : Capital punishment (the death penalty) has existed in the United States since before the United States was a country. As of 2017, capital punishment is legal in 30 of the 50 states. The federal government (including the United States military) also uses capital punishment.\n",
            "Relevance Score : 0.75\n",
            "\n",
            "\n",
            "Document Rank : 3, Document Index : 1\n",
            "Document : The Commonwealth of the Northern Mariana Islands is a group of islands in the Pacific Ocean that are a political division controlled by the United States. Its capital is Saipan.\n",
            "Relevance Score : 0.09\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rerank using JSON structure retrieved from Elastic search (email log)\n",
        "\n",
        "emails = [\n",
        "    {\n",
        "        \"from\": \"Paul Doe <paul_fake_doe@oracle.com>\",\n",
        "        \"to\": [\"Steve <steve@me.com>\", \"lisa@example.com\"],\n",
        "        \"date\": \"2024-03-27\",\n",
        "        \"subject\": \"Follow-up\",\n",
        "        \"text\": \"We are happy to give you the following pricing for your project.\"\n",
        "    },\n",
        "    {\n",
        "        \"from\": \"John McGill <john_fake_mcgill@microsoft.com>\",\n",
        "        \"to\": [\"Steve <steve@me.com>\"],\n",
        "        \"date\": \"2024-03-28\",\n",
        "        \"subject\": \"Missing Information\",\n",
        "        \"text\": \"Sorry, but here is the pricing you asked for for the newest line of your models.\"\n",
        "    },\n",
        "    {\n",
        "        \"from\": \"John McGill <john_fake_mcgill@microsoft.com>\",\n",
        "        \"to\": [\"Steve <steve@me.com>\"],\n",
        "        \"date\": \"2024-02-15\",\n",
        "        \"subject\": \"Commited Pricing Strategy\",\n",
        "        \"text\": \"I know we went back and forth on this during the call but the pricing for now should follow the agreement at hand.\"\n",
        "    },\n",
        "    {\n",
        "        \"from\": \"Generic Airline Company<no_reply@generic_airline_email.com>\",\n",
        "        \"to\": [\"Steve <steve@me.com>\"],\n",
        "        \"date\": \"2023-07-25\",\n",
        "        \"subject\": \"Your latest flight travel plans\",\n",
        "        \"text\": \"Thank you for choose to fly Generic Airline Company. Your booking status is confirmed.\"\n",
        "    },\n",
        "    {\n",
        "        \"from\": \"Generic SaaS Company<marketing@generic_saas_email.com>\",\n",
        "        \"to\": [\"Steve <steve@me.com>\"],\n",
        "        \"date\": \"2024-01-26\",\n",
        "        \"subject\": \"How to build generative AI applications using Generic Company Name\",\n",
        "        \"text\": \"Hey Steve! Generative AI is growing so quickly and we know you want to build fast!\"\n",
        "    },\n",
        "    {\n",
        "        \"from\": \"Paul Doe <paul_fake_doe@oracle.com>\",\n",
        "        \"to\": [\"Steve <steve@me.com>\", \"lisa@example.com\"],\n",
        "        \"date\": \"2024-04-09\",\n",
        "        \"subject\": \"Price Adjustment\",\n",
        "        \"text\": \"Re: our previous correspondence on 3/27 we'd like to make an amendment on our pricing proposal. We'll have to decrease the expected base price by 5%.\"\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "36thcz6Ej1yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_fields=[\"from\", \"to\",\"date\",\"subject\", \"text\" ]"
      ],
      "metadata": {
        "id": "sG35UdVMof_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"What is the pricing that we got from MS?\""
      ],
      "metadata": {
        "id": "LxCBA_l2okgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query,\n",
        "                    model=\"rerank-english-v3.0\",\n",
        "                    documents=emails,\n",
        "                    rank_fields=rank_fields,\n",
        "                    top_n=2)\n"
      ],
      "metadata": {
        "id": "_D1FPReYo0-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for hit in results.results:\n",
        "  email = emails[hit.index]\n",
        "  print(email)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRBeSYsRpMd-",
        "outputId": "e8830340-21a6-4aaa-99d2-d39e509809f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'from': 'Paul Doe <paul_fake_doe@oracle.com>', 'to': ['Steve <steve@me.com>', 'lisa@example.com'], 'date': '2024-03-27', 'subject': 'Follow-up', 'text': 'We are happy to give you the following pricing for your project.'}\n",
            "{'from': 'Paul Doe <paul_fake_doe@oracle.com>', 'to': ['Steve <steve@me.com>', 'lisa@example.com'], 'date': '2024-04-09', 'subject': 'Price Adjustment', 'text': \"Re: our previous correspondence on 3/27 we'd like to make an amendment on our pricing proposal. We'll have to decrease the expected base price by 5%.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What pricing we got from oracle?\""
      ],
      "metadata": {
        "id": "uKns9O9IpeGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG example\n",
        "\n",
        "documents = [\n",
        "    {\n",
        "        \"title\": \"Tall penguins\",\n",
        "        \"text\": \"Emperor penguins are the tallest.\"},\n",
        "    {\n",
        "        \"title\": \"Penguin habitats\",\n",
        "        \"text\": \"Emperor penguins only live in Antarctica.\"},\n",
        "    {\n",
        "        \"title\": \"What are animals?\",\n",
        "        \"text\": \"Animals are different from plants.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "3-Lp1NoU4ibp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"What are the tallest living penguins?\""
      ],
      "metadata": {
        "id": "UJ0yr6ZS4w0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = co.chat_stream(\n",
        "    message=message,\n",
        "    model=\"command-r-plus\",\n",
        "    documents=documents,\n",
        "\n",
        ")\n",
        "citations=[]\n",
        "cited_documents=[]\n",
        "\n",
        "for event in response:\n",
        "  if event.event_type== \"text-generation\":\n",
        "    print(event.text,end=\"\")\n",
        "  elif event.event_type == \"citation-generation\" :\n",
        "      citations.extend(event.citations)\n",
        "  elif event.event_type == \"stream-end\":\n",
        "      cited_documents=event.response.documents\n",
        "\n",
        "if citations:\n",
        "  print(\"\\n CITATIONS REFERENCE :\")\n",
        "  for citation in citations:\n",
        "    print(citation)\n",
        "\n",
        "  print(\"\\n DOCUMENT REFERENCES :\")\n",
        "  for document in cited_documents:\n",
        "    print(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfziokkH43zz",
        "outputId": "57095746-6a03-42db-ca87-0c5d6d3b5b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tallest living penguins are the Emperor penguins. They are the only penguins that live in Antarctica.\n",
            " CITATIONS REFERENCE :\n",
            "start=4 end=53 text='tallest living penguins are the Emperor penguins.' document_ids=['doc_0']\n",
            "start=67 end=105 text='only penguins that live in Antarctica.' document_ids=['doc_1']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "{'id': 'doc_0', 'text': 'Emperor penguins are the tallest.', 'title': 'Tall penguins'}\n",
            "{'id': 'doc_1', 'text': 'Emperor penguins only live in Antarctica.', 'title': 'Penguin habitats'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install unstructured hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i644AZqEVcf",
        "outputId": "58f014f7-1325-49a6-ffcc-8d29f2283361"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.14.10-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json (from unstructured)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.25.2)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.24.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->unstructured)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->unstructured)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.7.4)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.0)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from unstructured-client->unstructured)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (24.1)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-4.3.0-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Building wheels for collected packages: hnswlib, langdetect\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2331270 sha256=59dce776d00935d645e674abbe5036964f5ed2e993f05eb591ffc30f27d7b90b\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=19a296805b99d970da32be2d3fa7dadc0deb2f046c0b9292bca2adfcd337cf04\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built hnswlib langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, mypy-extensions, marshmallow, langdetect, jsonpath-python, hnswlib, emoji, backoff, typing-inspect, requests-toolbelt, deepdiff, dataclasses-json, unstructured-client, unstructured\n",
            "Successfully installed backoff-2.2.1 dataclasses-json-0.6.7 deepdiff-7.0.1 emoji-2.12.1 filetype-1.2.0 hnswlib-0.8.0 jsonpath-python-1.0.6 langdetect-1.0.9 marshmallow-3.21.3 mypy-extensions-1.0.0 ordered-set-4.1.0 pypdf-4.3.0 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.4 requests-toolbelt-1.0.0 typing-inspect-0.9.0 unstructured-0.14.10 unstructured-client-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cohere\n",
        "import uuid\n",
        "import hnswlib\n",
        "from typing import List, Dict\n",
        "from unstructured.partition.html import partition_html\n",
        "from unstructured.chunking.title import chunk_by_title\n"
      ],
      "metadata": {
        "id": "WvhJJHu-D_hn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_documents = [\n",
        "    {\n",
        "        \"title\": \"Text Embeddings\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
        "    {\n",
        "        \"title\": \"Similarity Between Words and Sentences\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
        "    {\n",
        "        \"title\": \"The Attention Mechanism\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
        "    {\n",
        "        \"title\": \"Transformer Models\",\n",
        "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}\n",
        "]"
      ],
      "metadata": {
        "id": "flRk0KHaEmdl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Vectorstore(raw_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvIgIEi6iTc9",
        "outputId": "ab4b8f8b-39cc-48da-811c-3504a8c0e510"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding document chunks\n",
            "Indexing document chunks\n",
            "Indexing complete with 166 document chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorstore :\n",
        "\n",
        "  def __init__ (self, raw_documents :List[Dict[str,str]]) :\n",
        "    self.raw_documents = raw_documents\n",
        "    self.docs = []\n",
        "    self.doc_embs = []\n",
        "    self.retrieve_top_k = 10\n",
        "    self.rerank_top_k = 3\n",
        "    self.load_and_chunk()\n",
        "    self.embed()\n",
        "    self.index()\n",
        "\n",
        "  def load_and_chunk(self)  -> None :\n",
        "\n",
        "    for raw_document in self.raw_documents :\n",
        "      elements = partition_html(url=raw_document[\"url\"])\n",
        "      chunks = chunk_by_title(elements)\n",
        "      for chunk in chunks :\n",
        "        self.docs.append(\n",
        "            {\n",
        "                \"title\" : raw_document[\"title\"],\n",
        "                \"text\" : str(chunk),\n",
        "                \"url\" : raw_document[\"url\"]\n",
        "            }\n",
        "        )\n",
        "\n",
        " # print(docs)\n",
        "\n",
        "  def embed(self)  -> None :\n",
        "    print(\"Embedding document chunks\")\n",
        "\n",
        "    batch_size = 90\n",
        "    self.docs_len = len(self.docs)\n",
        "\n",
        "    for i in range(0, self.docs_len, batch_size) :\n",
        "      batch = self.docs[i : min(i+batch_size,self.docs_len)]\n",
        "      texts=[item[\"text\"] for item in batch]\n",
        "      docs_embs_batch = co.embed(\n",
        "          texts=texts, model=\"embed-english-v3.0\",\n",
        "          input_type=\"search_document\"\n",
        "      ).embeddings\n",
        "\n",
        "      self.doc_embs.extend(docs_embs_batch)\n",
        "\n",
        "\n",
        "  def index(self)  -> None :\n",
        "    print (\"Indexing document chunks\")\n",
        "    self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
        "    self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
        "    self.idx.add_items(self.doc_embs,list(range(len(self.doc_embs))))\n",
        "\n",
        "    print(f\"Indexing complete with {self.idx.get_current_count()} document chunks\")\n",
        "\n",
        "  def retrieve(self, query : str) -> List[Dict[str,str]] :\n",
        "      print(\"Retrieving documents\")\n",
        "\n",
        "      query_emb = co.embed(\n",
        "          texts=[query], model=\"embed-english-v3.0\",\n",
        "          input_type=\"search_query\"\n",
        "      ).embeddings\n",
        "\n",
        "\n",
        "      #doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
        "\n",
        "      # Assign a value to doc_ids here\n",
        "      doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Reranking feature\n",
        "\n",
        "\n",
        "\n",
        "      rank_fields = [\"title\", \"text\"]\n",
        "\n",
        "      docs_to_rerank = [self.docs[doc_id] for doc_id in doc_ids]\n",
        "\n",
        "      rerank_results = co.rerank(\n",
        "            query=query,\n",
        "            model=\"rerank-english-v3.0\",\n",
        "            documents=docs_to_rerank,\n",
        "            rank_fields=rank_fields,\n",
        "            top_n=self.rerank_top_k\n",
        "            )\n",
        "\n",
        "      doc_ids_reranked = [doc_ids[result.index] for result in rerank_results.results]\n",
        "\n",
        "      docs_retrieved = []\n",
        "      for doc_id in doc_ids_reranked:\n",
        "        docs_retrieved.append(\n",
        "              {\n",
        "                  \"title\" : self.docs[doc_id][\"title\"],\n",
        "                  \"text\" : self.docs[doc_id][\"text\"],\n",
        "                  \"url\" : self.docs[doc_id][\"url\"]\n",
        "              }\n",
        "              )\n",
        "\n",
        "      return docs_retrieved\n",
        "\n"
      ],
      "metadata": {
        "id": "IFmpZXJWI6rp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot :\n",
        "\n",
        "  def __init__(self, vectorstore : Vectorstore) :\n",
        "    self.vectorstore = vectorstore\n",
        "    self.conversation_id = str(uuid.uuid4())\n",
        "\n",
        "  def run(self) :\n",
        "\n",
        "    while(True) :\n",
        "      print(f\"\\n{'-' * 100} \\n\")\n",
        "\n",
        "      message = input(\"User : \")\n",
        "\n",
        "      if message.lower() == \"quit\" :\n",
        "        print (\"Ending chat\")\n",
        "        break\n",
        "\n",
        "      response = co.chat(message = message,\n",
        "                         model = \"command-r\",\n",
        "                         search_queries_only = True)\n",
        "\n",
        "      if response.search_queries :\n",
        "        print(\"Retriveing information\", end=\"\")\n",
        "\n",
        "        documents = []\n",
        "\n",
        "        for query in response.search_queries :\n",
        "          documents.extend(self.vectorstore.retrieve(query.text))\n",
        "\n",
        "        response = co.chat_stream(\n",
        "            message=message,\n",
        "            model=\"command-r-plus\",\n",
        "            documents=documents,\n",
        "            conversation_id=self.conversation_id\n",
        "        )\n",
        "\n",
        "      else :\n",
        "        response = co.chat_stream(\n",
        "                        message=message,\n",
        "                        model=\"command-r-plus\",\n",
        "                        conversation_id=self.conversation_id\n",
        "                )\n",
        "\n",
        "      print(\"\\n Chatbot: \")\n",
        "\n",
        "      citations = []\n",
        "      cited_documents = []\n",
        "\n",
        "      for event in response :\n",
        "        if event.event_type == \"text-generation\" :\n",
        "          print(event.text, end=\"\")\n",
        "        elif event.event_type == \"citation-generation\" :\n",
        "          citations.extend(event.citations)\n",
        "        elif event.event_type == \"stream-end\" :\n",
        "          cited_documents = event.response.documents\n",
        "\n",
        "      if citations :\n",
        "        print(\"\\n \\nCITATIONS REFERENCE :\")\n",
        "        for citation in citations:\n",
        "          print(citation)\n",
        "\n",
        "        print(\"\\n \\nDOCUMENT REFERENCES :\")\n",
        "        for document in cited_documents:\n",
        "          print(document)"
      ],
      "metadata": {
        "id": "BxYjikKNi1G6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = Chatbot(vectorstore)\n",
        "chatbot.run()"
      ],
      "metadata": {
        "id": "3N0F0mp8qZpA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af2c44f-e3da-4f71-fcfb-4149229924a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "User : what is attention\n",
            "Retriveing informationRetrieving documents\n",
            "\n",
            " Chatbot: \n",
            "Attention is a technique used in transformer models to help language models understand context. It helps give context to each word in a sentence or text based on the other words surrounding it.\n",
            " \n",
            "CITATIONS REFERENCE :\n",
            "start=15 end=24 text='technique' document_ids=['doc_0']\n",
            "start=33 end=51 text='transformer models' document_ids=['doc_0', 'doc_1', 'doc_2']\n",
            "start=60 end=95 text='language models understand context.' document_ids=['doc_0']\n",
            "start=110 end=130 text='context to each word' document_ids=['doc_1', 'doc_2']\n",
            "start=136 end=152 text='sentence or text' document_ids=['doc_2']\n",
            "start=166 end=193 text='other words surrounding it.' document_ids=['doc_2']\n",
            "\n",
            " \n",
            "DOCUMENT REFERENCES :\n",
            "{'id': 'doc_0', 'text': 'Attention is a very useful technique that helps language models understand the context. In order to understand how attention works, consider the following two sentences:\\n\\nSentence 1: The bank of the river.\\n\\nSentence 2: Money in the bank.', 'title': 'Transformer Models', 'url': 'https://docs.cohere.com/docs/transformer-models'}\n",
            "{'id': 'doc_1', 'text': 'We can train such a large network, but we can vastly improve it by adding a key step: the attention component. Introduced in the seminal paper Attention is All you Need, it is one of the key ingredients in transformer models, and one of the reasons they work so well. Attention is explained in the previous section, but for now, imagine it as a way to add context to each word in the text.', 'title': 'Transformer Models', 'url': 'https://docs.cohere.com/docs/transformer-models'}\n",
            "{'id': 'doc_2', 'text': 'Attention helps give context to each word, based on the other words in the sentence (or text).', 'title': 'Transformer Models', 'url': 'https://docs.cohere.com/docs/transformer-models'}\n",
            "\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "User : quit\n",
            "Ending chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG with Connectors\n",
        "\n",
        "import uuid\n",
        "import cohere\n",
        "from cohere import ChatConnector\n",
        "from typing import List\n",
        "\n"
      ],
      "metadata": {
        "id": "7i98lwW53OAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chatbot :\n",
        "  def __init__(self, connector : List[str]) :\n",
        "    self.conversation_id = str(uuid.uuid4())\n",
        "    self.connectors = [ChatConnector(id=connector) for connector in connectors]\n",
        "\n",
        "  def run(self) :\n",
        "\n",
        "      while(True) :\n",
        "        print(f\"\\n{'-' * 100} \\n\")\n",
        "\n",
        "        message = input(\"User : \")\n",
        "\n",
        "        if message.lower() == \"quit\" :\n",
        "          print (\"Ending chat\")\n",
        "          break\n",
        "\n",
        "        response = co.chat_stream(\n",
        "            message=message,\n",
        "            model=\"command-r-plus\",\n",
        "            connectors=self.connectors,\n",
        "            conversation_id=self.conversation_id\n",
        "        )\n",
        "\n",
        "        print(\"\\n Chatbot: \")\n",
        "\n",
        "        citations=[]\n",
        "        cited_documents=[]\n",
        "\n",
        "        for event in response:\n",
        "          if event.event_type== \"text-generation\":\n",
        "              print(event.text,end=\"\")\n",
        "          elif event.event_type == \"citation-generation\" :\n",
        "                citations.extend(event.citations)\n",
        "          elif event.event_type == \"stream-end\":\n",
        "                cited_documents=event.response.documents\n",
        "\n",
        "\n",
        "          if citations:\n",
        "            print(\"\\n CITATIONS REFERENCE :\")\n",
        "            for citation in citations:\n",
        "              print(citation)\n",
        "\n",
        "            print(\"\\n DOCUMENT REFERENCES :\")\n",
        "            for document in cited_documents:\n",
        "              print({\"id\": document[\"id\"],\n",
        "                    'sinppet':document['snippet'][:400]+ '....',\n",
        "                    'title':document['title'],\n",
        "                    'url':document['url']})\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3IJfJ7tF3gs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connectors = ['web-search']\n",
        "chatbot = Chatbot(connectors)\n",
        "chatbot.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXAkieqJ5uw6",
        "outputId": "378abe25-4497-48fa-c02c-b4c3850d4128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "User : explain cohere\n",
            "\n",
            " Chatbot: \n",
            "Cohere is a leading AI platform for enterprise. Our world-class AI is uniquely suited to the needs of businesses, unlocking unprecedented ease-of-use, accessibility, and data privacy. Cohere’s platform is cloud-agnostic, accessible through API as a managed service, and can be deployed on virtual private cloud (VPC) or even on-site to meet companies where their data is, offering the highest levels of flexibility and control. Cohere is on a mission to transform enterprises and their products with AI that unlocks a more intuitive way to generate, search, and summarize information than ever before.\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "start=221 end=264 text='accessible through API as a managed service' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "start=221 end=264 text='accessible through API as a managed service' document_ids=['web-search_2']\n",
            "start=277 end=332 text='deployed on virtual private cloud (VPC) or even on-site' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "start=221 end=264 text='accessible through API as a managed service' document_ids=['web-search_2']\n",
            "start=277 end=332 text='deployed on virtual private cloud (VPC) or even on-site' document_ids=['web-search_2']\n",
            "start=385 end=427 text='highest levels of flexibility and control.' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "start=221 end=264 text='accessible through API as a managed service' document_ids=['web-search_2']\n",
            "start=277 end=332 text='deployed on virtual private cloud (VPC) or even on-site' document_ids=['web-search_2']\n",
            "start=385 end=427 text='highest levels of flexibility and control.' document_ids=['web-search_2']\n",
            "start=443 end=494 text='mission to transform enterprises and their products' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "start=221 end=264 text='accessible through API as a managed service' document_ids=['web-search_2']\n",
            "start=277 end=332 text='deployed on virtual private cloud (VPC) or even on-site' document_ids=['web-search_2']\n",
            "start=385 end=427 text='highest levels of flexibility and control.' document_ids=['web-search_2']\n",
            "start=443 end=494 text='mission to transform enterprises and their products' document_ids=['web-search_2']\n",
            "start=518 end=583 text='more intuitive way to generate, search, and summarize information' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "\n",
            " CITATIONS REFERENCE :\n",
            "start=12 end=47 text='leading AI platform for enterprise.' document_ids=['web-search_0', 'web-search_2']\n",
            "start=52 end=66 text='world-class AI' document_ids=['web-search_2']\n",
            "start=70 end=112 text='uniquely suited to the needs of businesses' document_ids=['web-search_2']\n",
            "start=124 end=183 text='unprecedented ease-of-use, accessibility, and data privacy.' document_ids=['web-search_2']\n",
            "start=205 end=219 text='cloud-agnostic' document_ids=['web-search_2']\n",
            "start=221 end=264 text='accessible through API as a managed service' document_ids=['web-search_2']\n",
            "start=277 end=332 text='deployed on virtual private cloud (VPC) or even on-site' document_ids=['web-search_2']\n",
            "start=385 end=427 text='highest levels of flexibility and control.' document_ids=['web-search_2']\n",
            "start=443 end=494 text='mission to transform enterprises and their products' document_ids=['web-search_2']\n",
            "start=518 end=583 text='more intuitive way to generate, search, and summarize information' document_ids=['web-search_2']\n",
            "\n",
            " DOCUMENT REFERENCES :\n",
            "{'id': 'web-search_0', 'sinppet': 'Introducing Command R+: Our new, most powerful model in the Command R family. Learn More\\n\\nThe Leading Enterprise AI Platform\\n\\nBuilt on the language of business\\n\\nOptimized for enterprise generative AI, search and discovery, and advanced retrieval.\\n\\nOur models are designed to augment and elevate the global workforce, so businesses can thrive and stay competitive in the AI era.\\n\\nCohere Command, power....', 'title': 'Cohere | The leading AI platform for enterprise', 'url': 'https://cohere.com/'}\n",
            "{'id': 'web-search_2', 'sinppet': 'Skip to main content\\n\\nSoftware Development\\n\\nToronto, Ontario 81,982 followers\\n\\nAt Cohere, our mission is to build machines that understand the world, and to make them safely accessible to all.\\n\\nView all 556 employees\\n\\nCohere is the leading AI platform for enterprise. Our world-class AI is uniquely suited to the needs of business, unlocking unprecedented ease-of-use, accessibility, and data privacy....', 'title': 'Cohere | LinkedIn', 'url': 'https://www.linkedin.com/company/cohere-ai/'}\n",
            "\n",
            "---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "User : quit\n",
            "Ending chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using multiple connectors\n",
        "\n",
        "connectors = [\"<GDRIVE Connector name>\",'web-search']\n",
        "chatbot = Chatbot(connectors)\n",
        "chatbot.run()"
      ],
      "metadata": {
        "id": "blUehxdN_6uH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}